# ğŸ¦† Arquitectura Bronce y Silver con DuckDB

Este documento describe cÃ³mo se implementÃ³ el sistema de ingesta y transformaciÃ³n de datos desde archivos CSV hacia un **Lakehouse local usando DuckDB**, estructurado por capas: **Bronce** y **Silver**.

---

## ğŸ“ Estructura del Lakehouse

data/
â””â”€â”€ lake/
â”œâ”€â”€ bronze/
â”‚ â”œâ”€â”€ sensor_data/
â”‚ â”œâ”€â”€ equipos/
â”‚ â””â”€â”€ eventos/
â””â”€â”€ silver/
â”œâ”€â”€ lecturas_filtradas/
â”œâ”€â”€ eventos_procesados/
â”œâ”€â”€ equipos_enriquecidos/
â””â”€â”€ pozos_catalogo/
warehouse.duckdb

---

## ğŸ§Š Capa Bronce (Raw + Metadata)

Los archivos CSV se ingestan a Bronce utilizando `Polars` y `DuckDB`. En esta capa:

- Se agregan las columnas:
  - `pozo`: extraÃ­da del nombre del archivo
  - `id_ingestion`: UUID Ãºnico
  - `source_file`: nombre del archivo de origen
  - `ingestion_timestamp`: fecha y hora de ingesta
- Las fechas se tipan a `datetime[Î¼s, America/Mexico_City]`
- Las columnas numÃ©ricas se convierten a `Float64`

### âœ… Tablas Bronce

| Tabla           | DescripciÃ³n                                |
|-----------------|--------------------------------------------|
| `bronze.sensor_data` | Lecturas crudas por sensor               |
| `bronze.equipos`     | Datos de configuraciÃ³n de equipos        |
| `bronze.eventos`     | Paros programados/no programados         |
| `bronze.ingested_files` | Control de archivos ya ingestados      |

---

## âš™ï¸ Capa Silver (ValidaciÃ³n y TransformaciÃ³n)

En Silver se aplican transformaciones de negocio con `Polars`. Los datos se interpolan, filtran y enriquecen para asegurar consistencia temporal y relacional.

### âœ… Tablas Silver

| Tabla                         | DescripciÃ³n                                                                 |
|-------------------------------|-----------------------------------------------------------------------------|
| `silver.lecturas_silver`      | Lecturas interpoladas cada 10 minutos por pozo y nÃºmero de equipo           |
| `silver.sensor_coverage_silver` | CatÃ¡logo de sensores disponibles por equipo                                |
| `silver.equipos_silver`       | Datos tÃ©cnicos de equipos + estado calculado (`activo` / `inactivo`)        |
| `silver.eventos_silver`       | Eventos enriquecidos con `numero_equipo`, segÃºn ventana de operaciÃ³n        |
| `silver.pozos_silver`         | Resumen por pozo: Ãºltima fecha de operaciÃ³n, estado actual, nÃºmero de equipos |

---

### Funciones Clave aplicadas

- `prepare_equipos`: asigna estado `"activo"` o `"inactivo"` segÃºn la fecha de salida del equipo.
- `filtrar_sensores_validos`: conserva solo las lecturas dentro del perÃ­odo de operaciÃ³n del equipo.
- `interpolar_por_equipo`: interpola lecturas cada 10 minutos.
- `generar_catalogo`: identifica los sensores vÃ¡lidos para cada equipo.
- `preparar_eventos`: estandariza eventos desde Bronce.
- `enriquecer_eventos_con_equipo`: asigna `numero_equipo` a eventos segÃºn fechas.
- `generar_tabla_pozos`: resume el estado y cantidad de equipos por pozo.

### ğŸ• Zonas Horarias

- Toda la lÃ³gica trabaja en `datetime[Î¼s, America/Mexico_City]`
- Se evita el uso de UTC para mantener coherencia y facilidad de debugging local

---

## âœ… Buenas prÃ¡cticas aplicadas

- Ingesta incremental basada en `ingested_files`.
- SeparaciÃ³n entre datos crudos (Bronce) y validados (Silver).
- TransformaciÃ³n eficiente y vectorizada con `Polars`.
- InterpolaciÃ³n controlada por equipo y por sensor.
- Registro automÃ¡tico de vistas externas en DuckDB.

---

## ğŸ§ª Verificaciones recomendadas

```python
con = duckdb.connect(\"warehouse.duckdb\")
df = con.execute(\"SELECT * FROM bronze.sensor_data LIMIT 5\").arrow()
pl.from_arrow(df).schema
```

---

## ğŸš§ PrÃ³ximos pasos sugeridos
* Incorporar capa Gold para KPIs agregados o dashboards.
* Agregar validaciones automÃ¡ticas de calidad de datos.
* Integrar modelos predictivos (ML) sobre tablas Silver.
* Automatizar orquestaciÃ³n completa con sensores de archivos.
* Agregar dbt para modelado declarativo

# ğŸŸ¡ Estructura de las Tablas Gold (`itzamna_dbt`)

Las tablas en la capa **Gold** representan vistas transformadas y listas para anÃ¡lisis avanzado, especialmente orientadas a tareas de NLP como recuperaciÃ³n aumentada por generaciÃ³n (RAG). A continuaciÃ³n se describe la estructura de cada tabla:

---

## ğŸ“˜ `main_gold.sensor_cobertura_real`

### ğŸ§± DescripciÃ³n
Tabla que indica la cobertura de cada sensor (porcentaje de datos vÃ¡lidos) por combinaciÃ³n de `pozo` y `numero_equipo`.

### ğŸ“ Esquema

| Columna             | Tipo       | DescripciÃ³n                                                                 |
|---------------------|------------|-----------------------------------------------------------------------------|
| `pozo`              | `VARCHAR`  | Identificador del pozo.                                                    |
| `numero_equipo`     | `INTEGER`  | NÃºmero del equipo dentro del pozo.                                         |
| `sensor`            | `VARCHAR`  | Nombre del sensor registrado en `lecturas_silver`.                         |
| `total_registros`   | `INTEGER`  | Total de registros para ese sensor en esa combinaciÃ³n pozo-equipo.         |
| `registros_validos` | `INTEGER`  | Registros que no son `NULL` para el sensor.                                |
| `porcentaje_valido` | `FLOAT`    | ProporciÃ³n `registros_validos / total_registros`.                          |

### ğŸ” Consideraciones
- SÃ³lo se incluyen sensores cuyo `porcentaje_valido >= 0.9`.
- Ãštil para filtrar sensores no operativos o irrelevantes por baja cobertura.

---

## ğŸ“˜ `main_gold.document_chunks`

### ğŸ§± DescripciÃ³n
Tabla que agrupa y convierte las lecturas de sensores vÃ¡lidos en documentos diarios por equipo y pozo. Cada documento es un chunk textual con formato legible para tareas de NLP.

### ğŸ“ Esquema

| Columna         | Tipo        | DescripciÃ³n                                                                 |
|------------------|-------------|-----------------------------------------------------------------------------|
| `id`             | `VARCHAR`   | ID Ãºnico: `pozo-numero_equipo-fecha (YYYYMMDD)`.                           |
| `content`        | `TEXT`      | Texto plano con las lecturas del dÃ­a agrupadas por sensor y timestamp.     |
| `pozo`           | `VARCHAR`   | Identificador del pozo.                                                    |
| `numero_equipo`  | `INTEGER`   | NÃºmero del equipo dentro del pozo.                                         |
| `fecha`          | `DATE`      | Fecha (a nivel dÃ­a) de los datos agregados.                                |

### ğŸ” Formato del campo `content`
```text
2023-08-24 00:00 | Corriente de entrada: 8.4
2023-08-24 00:10 | Corriente de entrada: 8.7
2023-08-24 00:20 | Corriente de entrada: 8.9
```

## ğŸ§  Aplicaciones
- Entrada directa para generaciÃ³n de embeddings (OpenAI, HuggingFace, Vertex AI).
- Ideal para bÃºsqueda semÃ¡ntica o recuperaciÃ³n de contexto para LLMs.

## ğŸ”„ RelaciÃ³n entre tablas
- document_chunks depende de los sensores vÃ¡lidos definidos en sensor_cobertura_real.
- Ambas se derivan de la tabla silver.lecturas_silver, pero document_chunks filtra y estructura los datos de forma legible.

## ğŸ§ª Siguiente paso sugerido
Indexar document_chunks con una base de datos vectorial y usarlo como fuente en un pipeline de Retrieval-Augmented Generation (RAG).