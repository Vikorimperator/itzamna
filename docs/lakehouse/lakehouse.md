# ğŸ¦† Arquitectura Bronce y Silver con DuckDB

Este documento describe cÃ³mo se implementÃ³ el sistema de ingesta y transformaciÃ³n de datos desde archivos CSV hacia un **Lakehouse local usando DuckDB**, estructurado por capas: **Bronce** y **Silver**.

---

## ğŸ“ Estructura del Lakehouse

data/
â””â”€â”€ lake/
â”œâ”€â”€ bronze/
â”‚ â”œâ”€â”€ sensor_data/
â”‚ â”œâ”€â”€ equipos/
â”‚ â””â”€â”€ eventos/
â””â”€â”€ silver/
â”œâ”€â”€ lecturas_filtradas/
â”œâ”€â”€ eventos_procesados/
â”œâ”€â”€ equipos_enriquecidos/
â””â”€â”€ pozos_catalogo/
warehouse.duckdb

---

## ğŸ§Š Capa Bronce (Raw + Metadata)

Los archivos CSV se ingestan a Bronce utilizando `Polars` y `DuckDB`. En esta capa:

- Se agregan las columnas:
  - `pozo`: extraÃ­da del nombre del archivo
  - `id_ingestion`: UUID Ãºnico
  - `source_file`: nombre del archivo de origen
  - `ingestion_timestamp`: fecha y hora de ingesta
- Las fechas se tipan a `datetime[Î¼s, America/Mexico_City]`
- Las columnas numÃ©ricas se convierten a `Float64`

### âœ… Tablas Bronce

| Tabla           | DescripciÃ³n                                |
|-----------------|--------------------------------------------|
| `bronze.sensor_data` | Lecturas crudas por sensor               |
| `bronze.equipos`     | Datos de configuraciÃ³n de equipos        |
| `bronze.eventos`     | Paros programados/no programados         |
| `bronze.ingested_files` | Control de archivos ya ingestados      |

---

## âš™ï¸ Capa Silver (ValidaciÃ³n y TransformaciÃ³n)

En Silver se aplican transformaciones de negocio con `Polars`. Los datos se interpolan, filtran y enriquecen para asegurar consistencia temporal y relacional.

### âœ… Tablas Silver

| Tabla                         | DescripciÃ³n                                                                 |
|-------------------------------|-----------------------------------------------------------------------------|
| `silver.lecturas_silver`      | Lecturas interpoladas cada 10 minutos por pozo y nÃºmero de equipo           |
| `silver.sensor_coverage_silver` | CatÃ¡logo de sensores disponibles por equipo                                |
| `silver.equipos_silver`       | Datos tÃ©cnicos de equipos + estado calculado (`activo` / `inactivo`)        |
| `silver.eventos_silver`       | Eventos enriquecidos con `numero_equipo`, segÃºn ventana de operaciÃ³n        |
| `silver.pozos_silver`         | Resumen por pozo: Ãºltima fecha de operaciÃ³n, estado actual, nÃºmero de equipos |

---

### Funciones Clave aplicadas

- `prepare_equipos`: asigna estado `"activo"` o `"inactivo"` segÃºn la fecha de salida del equipo.
- `filtrar_sensores_validos`: conserva solo las lecturas dentro del perÃ­odo de operaciÃ³n del equipo.
- `interpolar_por_equipo`: interpola lecturas cada 10 minutos.
- `generar_catalogo`: identifica los sensores vÃ¡lidos para cada equipo.
- `preparar_eventos`: estandariza eventos desde Bronce.
- `enriquecer_eventos_con_equipo`: asigna `numero_equipo` a eventos segÃºn fechas.
- `generar_tabla_pozos`: resume el estado y cantidad de equipos por pozo.

### ğŸ• Zonas Horarias

- Toda la lÃ³gica trabaja en `datetime[Î¼s, America/Mexico_City]`
- Se evita el uso de UTC para mantener coherencia y facilidad de debugging local

---

## âœ… Buenas prÃ¡cticas aplicadas

- Ingesta incremental basada en `ingested_files`.
- SeparaciÃ³n entre datos crudos (Bronce) y validados (Silver).
- TransformaciÃ³n eficiente y vectorizada con `Polars`.
- InterpolaciÃ³n controlada por equipo y por sensor.
- Registro automÃ¡tico de vistas externas en DuckDB.

---

## ğŸ§ª Verificaciones recomendadas

```python
con = duckdb.connect(\"warehouse.duckdb\")
df = con.execute(\"SELECT * FROM bronze.sensor_data LIMIT 5\").arrow()
pl.from_arrow(df).schema
```

---

## ğŸš§ PrÃ³ximos pasos sugeridos
* Incorporar capa Gold para KPIs agregados o dashboards.
* Agregar validaciones automÃ¡ticas de calidad de datos.
* Integrar modelos predictivos (ML) sobre tablas Silver.
* Automatizar orquestaciÃ³n completa con sensores de archivos.
* Agregar dbt para modelado declarativo