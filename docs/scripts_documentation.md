
#  Documentaci贸n de Scripts - Proyecto Itzamna

Este documento describe la funcionalidad de los scripts clave que componen el pipeline de datos para el proyecto Itzamna.

---

## `run_pipeline.py`

- **Ubicaci贸n**: `/run_pipeline.py`
- **Prop贸sito**: Orquestar la ejecuci贸n del pipeline para:
  1. Inicializar el esquema de la base de datos bronce.
  2. Ingresar autom谩ticamente los archivos `.csv` detectados.
- **Entradas**: 
  - Archivos `.csv` ubicados en la carpeta `data/raw/`.
  - Script SQL `schema_bronze.sql` para la creaci贸n de tablas.
- **Salidas**:
  - Tablas creadas en PostgreSQL bajo el esquema `bronce`.
  - Datos cargados a las tablas correspondientes.
  - Logs registrados en `pipeline.log`.
- **Funciones involucradas**:
  - `init_bronze_schema()` de `src.utils.init_db`: ejecuta `schema_bronze.sql`.
  - `auto_discover_and_ingest()` de `src.data_ingestion.load_csv`: automatiza la carga de archivos.
  - `setup_logging()` de `src.utils.logging_config`: configura el logging.
- **Dependencias**:
  - `logging`, `src.utils`, `src.data_ingestion`
- **Ejecuci贸n recomendada**:
  ```bash
  python run_pipeline.py
  ```
- **Notas**:
  - El sistema captura errores y los registra con `logging.exception`.
  - Requiere que el archivo `.env` est茅 presente y correctamente configurado para la conexi贸n a la base de datos.


---

## `src/utils/config.py`

- **Ubicaci贸n**: `src/utils/config.py`
- **Prop贸sito**: Definir rutas del proyecto y proporcionar la URL de conexi贸n a la base de datos de Bronce desde variables de entorno.
- **Clases**:
  - `Paths`: Clase que centraliza las rutas importantes del proyecto.
    - `PROJECT_ROOT`: Directorio ra铆z del proyecto (2 niveles arriba del archivo actual).
    - `RAW_DATA`: Ruta donde se encuentran los archivos crudos (`/data/raw`).
    - `PROCESSED_DATA`: Ruta prevista para almacenar datos transformados (`/data/processed`).
    - `BRONZE_DB_URL`: Cadena de conexi贸n a la base de datos PostgreSQL, obtenida desde `.env`.
- **Dependencias**:
  - `pathlib`, `os`, `dotenv`
- **Notas**:
  - Este archivo permite mantener centralizadas las rutas y configuraciones clave, facilitando su reutilizaci贸n en otros m贸dulos.


---

## `src/utils/logging_config.py`

- **Ubicaci贸n**: `src/utils/logging_config.py`
- **Prop贸sito**: Configurar el sistema de logging del proyecto para registrar en consola y en archivo.
- **Funciones**:
  - `setup_logging(level=logging.INFO)`: Configura el nivel de logging, el formato y los handlers:
    - Archivo `pipeline.log` en el directorio ra铆z del proyecto.
    - Salida est谩ndar (consola).
- **Notas**:
  - Es recomendable llamar a esta funci贸n al inicio del script principal para asegurar el registro de toda la ejecuci贸n.

---

## `src/utils/init_db.py`

- **Ubicaci贸n**: `src/utils/init_db.py`
- **Prop贸sito**: Inicializa el esquema de la base de datos Bronce ejecutando el script SQL correspondiente.
- **Funciones**:
  - `init_bronze_schema()`: Ejecuta el archivo `schema_bronze.sql` para crear o verificar tablas en la base de datos PostgreSQL.
- **Entradas**:
  - `schema_bronze.sql` en la ruta `database/`.
- **Dependencias**:
  - `sqlalchemy`, `logging`, `pathlib`
- **Notas**:
  - Usa SQLAlchemy para crear una conexi贸n segura con la base de datos.
  - Registra cualquier error que ocurra al ejecutar el SQL.

---

## `src/data_ingestion/load_csv.py`

- **Ubicaci贸n**: `src/data_ingestion/load_csv.py`
- **Prop贸sito**: Automatizar la ingesti贸n de archivos `.csv` crudos a las tablas de Bronce correspondientes seg煤n su patr贸n de nombre.
- **Funciones principales**:
  - `ingest_sensor_data(csv_path, well_id)`
  - `ingest_equipos_data(csv_path, well_id)`
  - `ingest_eventos_data(csv_path, well_id)`
  - `is_file_already_ingested(file_name)`
  - `register_ingested_file(file_name)`
  - `auto_discover_and_ingest()`: funci贸n orquestadora que detecta los archivos y llama a la funci贸n de ingesti贸n adecuada.
- **L贸gica de ingesti贸n**:
  - Detecta tipo de archivo usando expresiones regulares (sensor, equipos, eventos).
  - Genera columnas necesarias (`id_ingestion`, `ingestion_timestamp`, `source_file`, etc.).
  - Inserta los datos en la base de datos con `to_sql` (con chunking y sin 铆ndices).
  - Evita duplicados verificando si el archivo ya fue registrado.
- **Dependencias**:
  - `pandas`, `sqlalchemy`, `uuid`, `datetime`, `logging`, `os`, `re`, `pathlib`
- **Notas**:
  - Solo se aceptan archivos con extensi贸n `.csv` y nombres v谩lidos seg煤n los patrones definidos.
  - La funci贸n `auto_discover_and_ingest()` es llamada desde el script principal.